{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "from typing import DefaultDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def parse_bw(filepath, target):\n",
    "    if target < 0 or target > 5:\n",
    "        print('Wrong target range!')\n",
    "        sys.exit(1)\n",
    "        \n",
    "    \"\"\"\n",
    "    target\n",
    "    0: msg_size\n",
    "    1: iter\n",
    "    2: bw_peak\n",
    "    3: bw_avg\n",
    "    4: msg_rate\n",
    "    5: all\n",
    "    \"\"\"\n",
    "    res = []\n",
    "    \n",
    "    f = open(filepath, \"r\")\n",
    "    lines = f.readlines()\n",
    "    \n",
    "    startline = 0\n",
    "    for j in range(len(lines)):\n",
    "        if lines[j][0:4] == \" #by\":\n",
    "            startline = j + 1\n",
    "            break\n",
    "    endline = startline\n",
    "    while endline < len(lines):\n",
    "        if lines[endline][1:4] == '===':\n",
    "            break\n",
    "        endline += 1\n",
    "        \n",
    "    curline = startline\n",
    "    while curline < endline:\n",
    "        if lines[curline][0:2] == ' --':\n",
    "            break\n",
    "        if lines[curline][0] != ' ':\n",
    "            curline += 1\n",
    "            continue\n",
    "        line = lines[curline].split()\n",
    "        try:            \n",
    "            # (msg_size, iteration, bw_peak, bw_avg, msg_rate)\n",
    "            row = []\n",
    "            if target == 5:\n",
    "                row.append(line[0])\n",
    "                row.append(line[1])\n",
    "                row.append(line[2])\n",
    "                row.append(line[3])\n",
    "                row.append(line[4])\n",
    "            else:\n",
    "                row.append(line[target])\n",
    "            res.append(row)\n",
    "        except:\n",
    "            curline += 1\n",
    "            continue\n",
    "        curline += 1\n",
    "    \n",
    "    return res\n",
    "\n",
    "def parse_lat(filepath):\n",
    "    f = open(filepath, \"r\")\n",
    "    lines = f.readlines()\n",
    "    \n",
    "    startline = 0\n",
    "    for j in range(len(lines)):\n",
    "        if lines[j][0:4] == \" #by\":\n",
    "            startline = j + 1\n",
    "            break\n",
    "    endline = startline\n",
    "    while endline < len(lines):\n",
    "        if lines[endline][1:4] == '===':\n",
    "            break\n",
    "        endline += 1\n",
    "        \n",
    "    curline = startline\n",
    "    while curline < endline:\n",
    "        if lines[curline][0:2] == ' --':\n",
    "            break\n",
    "        if lines[curline][0] != ' ':\n",
    "            curline += 1\n",
    "            continue\n",
    "        line = lines[curline].split()\n",
    "        try:            \n",
    "            return line\n",
    "                \n",
    "        except:\n",
    "            curline += 1\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X3ProETH_y306_rb_t1_m512_bg1048576_s4096_tf\n",
      "['X3ProETH', 'y306', 'rb', '1', '512', '1048576', '3679.27', '0.003826', '4096', '386.71', '0.098997']\n",
      "[['X3ProETH', 'y306', 'rb', '1', '512', '1048576', '3679.27', '0.003826', '4096', '386.71', '0.098997']]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Output format = [[ data1 ], [data2], ... , columns = [] ]\n",
    "dataset = []\n",
    "columns = ['rnic', 'test_node', 'test_type', 'tx_depth', 'mtu', 'bg_msgsize', 'bg_bw', 'bg_msgrate', 'tar_msgsize', 'tar_bw', 'tar_msgrate']\n",
    "\n",
    "###################################\n",
    "## Modify Here\n",
    "TARGET = 'test_result_bw'\n",
    "OUTPUT = 'X3Pro_ETH_bw.csv'\n",
    "###################################\n",
    "\n",
    "target_dir = './' + TARGET\n",
    "if os.path.isdir(target_dir) == False:\n",
    "    print(\"Directory is not valid!\")\n",
    "    sys.exit()\n",
    "    \n",
    "file_list = os.listdir(target_dir)\n",
    "\n",
    "### Get target files ###\n",
    "target_list = []\n",
    "bw_t = ['rb', 'wb', 'sb']\n",
    "for target in file_list:\n",
    "    splt_target = target.split('_')\n",
    "    if splt_target[2] in bw_t and splt_target[7] == 'tf':\n",
    "        target_list.append(target)\n",
    "\n",
    "for t in target_list:\n",
    "    print(t)\n",
    "    row = []\n",
    "    splt_t = t.split('_')\n",
    "    \n",
    "    # add testing env\n",
    "    row.append(splt_t[0])\n",
    "    row.append(splt_t[1])\n",
    "    row.append(splt_t[2])\n",
    "    row.append(splt_t[3][1:])\n",
    "    row.append(splt_t[4][1:])\n",
    "    \n",
    "    # add bg_bw\n",
    "    bg_bw = parse_bw(target_dir + '/' + t[:-2] + 'bf', 5)[0]\n",
    "    avg_bw = parse_bw(target_dir + '/' + t[:-2] + 'bf', 3)[int(len(bg_bw)/2)][0]\n",
    "    row.append(bg_bw[0]) # msg size\n",
    "    row.append(avg_bw) # avg bw\n",
    "    row.append(bg_bw[4]) # msg rate\n",
    "    # add tar_bw data\n",
    "    tar_bw = parse_bw(target_dir + '/' + t, 5)[0]\n",
    "    row.append(tar_bw[0])\n",
    "    row.append(tar_bw[3])\n",
    "    row.append(tar_bw[4])\n",
    "\n",
    "    print(row)\n",
    "    dataset.append(row)\n",
    "    break\n",
    "\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       rnic test_node test_type tx_depth  mtu bg_msgsize    bg_bw bg_msgrate  \\\n",
      "0  X3ProETH      y306        rb        1  512    1048576  3679.27   0.003826   \n",
      "\n",
      "  tar_msgsize  tar_bw tar_msgrate  \n",
      "0        4096  386.71    0.098997  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(dataset, columns=columns)\n",
    "\n",
    "print(df)\n",
    "df.to_csv(OUTPUT)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "996a4fd48035787a0d8ee152fcdd352f02c743a60e71d5508e318f226822b2c7"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
