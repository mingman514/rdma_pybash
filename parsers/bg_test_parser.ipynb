{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "from typing import DefaultDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def parse_bw(filepath, target):\n",
    "    if target < 0 or target > 5:\n",
    "        print('Wrong target range!')\n",
    "        sys.exit(1)\n",
    "        \n",
    "    \"\"\"\n",
    "    target\n",
    "    0: msg_size\n",
    "    1: iter\n",
    "    2: bw_peak\n",
    "    3: bw_avg\n",
    "    4: msg_rate\n",
    "    5: all\n",
    "    \"\"\"\n",
    "    res = []\n",
    "    \n",
    "    f = open(filepath, \"r\")\n",
    "    lines = f.readlines()\n",
    "    \n",
    "    startline = 0\n",
    "    for j in range(len(lines)):\n",
    "        if lines[j][0:4] == \" #by\":\n",
    "            startline = j + 1\n",
    "            break\n",
    "    endline = startline\n",
    "    while endline < len(lines):\n",
    "        if lines[endline][1:4] == '===':\n",
    "            break\n",
    "        endline += 1\n",
    "        \n",
    "    curline = startline\n",
    "    while curline < endline:\n",
    "        if lines[curline][0:2] == ' --':\n",
    "            break\n",
    "        if lines[curline][0] != ' ':\n",
    "            curline += 1\n",
    "            continue\n",
    "        line = lines[curline].split()\n",
    "        try:            \n",
    "            # (msg_size, iteration, bw_peak, bw_avg, msg_rate)\n",
    "            if target == 5:\n",
    "                row = []\n",
    "                row.append(line[0])\n",
    "                row.append(line[1])\n",
    "                row.append(line[2])\n",
    "                row.append(line[3])\n",
    "                row.append(line[4])\n",
    "                res.append(row)\n",
    "            else:\n",
    "                res.append(line[target])\n",
    "        except:\n",
    "            curline += 1\n",
    "            continue\n",
    "        curline += 1\n",
    "    \n",
    "    return res\n",
    "\n",
    "def parse_lat(filepath):\n",
    "    f = open(filepath, \"r\")\n",
    "    lines = f.readlines()\n",
    "    \n",
    "    startline = 0\n",
    "    for j in range(len(lines)):\n",
    "        if lines[j][0:4] == \" #by\":\n",
    "            startline = j + 1\n",
    "            break\n",
    "    endline = startline\n",
    "    while endline < len(lines):\n",
    "        if lines[endline][1:4] == '===':\n",
    "            break\n",
    "        endline += 1\n",
    "        \n",
    "    curline = startline\n",
    "    while curline < endline:\n",
    "        if lines[curline][0:2] == ' --':\n",
    "            break\n",
    "        if lines[curline][0] != ' ':\n",
    "            curline += 1\n",
    "            continue\n",
    "        line = lines[curline].split()\n",
    "        try:            \n",
    "            return line\n",
    "                \n",
    "        except:\n",
    "            curline += 1\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X6ETH100_Y301_wb_t128_m1024_bg1024_tf\n",
      "['X6ETH100', 'Y301', 'wb', '128', '1024', '1024', '9307.31']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Output format = [[ data1 ], [data2], ... , columns = [] ]\n",
    "dataset = []\n",
    "columns = ['rnic', 'test_node', 'test_type', 'tx_depth', 'mtu', 'bg_msgsize', 'bg_bw', 'msgsize_tput', 'iter_tput', 'bw_peak_tput', 'bw_avg_tput', 'msgrate_tput', 'msgsize_lat', 'iter_lat', 't_min', 't_max', 't_typical', 't_avg', 't_stdev', '99th_percentile', '99.9th_percentile']\n",
    "\n",
    "###################################\n",
    "## Modify Here\n",
    "TARGET = 'test_result_taskset_w2'\n",
    "OUTPUT = 'X6_ETH100_taskset_w2.csv'\n",
    "###################################\n",
    "\n",
    "target_dir = './' + TARGET\n",
    "if os.path.isdir(target_dir) == False:\n",
    "    print(\"Directory is not valid!\")\n",
    "    sys.exit()\n",
    "    \n",
    "file_list = os.listdir(target_dir)\n",
    "\n",
    "### Get target files ###\n",
    "target_list = []\n",
    "bw_t = ['rb', 'wb', 'sb']\n",
    "for target in file_list:\n",
    "    splt_target = target.split('_')\n",
    "    if splt_target[2] in bw_t and splt_target[6] == 'tf':\n",
    "        target_list.append(target)\n",
    "\n",
    "for t in target_list:\n",
    "    print(t)\n",
    "    row = []\n",
    "    splt_t = t.split('_')\n",
    "    \n",
    "    # add testing env\n",
    "    row.append(splt_t[0])\n",
    "    row.append(splt_t[1])\n",
    "    row.append(splt_t[2])\n",
    "    row.append(splt_t[3][1:])\n",
    "    row.append(splt_t[4][1:])\n",
    "    row.append(splt_t[5][2:])\n",
    "    \n",
    "    # add bg_bw\n",
    "    bws = parse_bw(target_dir + '/' + t[:-2] + 'bf', 3)\n",
    "    row.append(bws[int(len(bws)/2)])\n",
    "    print(row)\n",
    "    # add tput data\n",
    "    tput_data = parse_bw(target_dir + '/' + t, 5)[0]\n",
    "    for e in tput_data:\n",
    "        row.append(e)\n",
    "    \n",
    "    # add latency data\n",
    "    try:\n",
    "        lat_data = parse_lat(target_dir + '/' + t.split('b_')[0] + 'l_' + t.split('b_')[1])\n",
    "    except:\n",
    "        print('File Not Exist: ' + target_dir + '/' + t.split('b_')[0] + 'l_' + t.split('b_')[1])\n",
    "        lat_data = [None] * 9\n",
    "    \n",
    "    for e in lat_data:\n",
    "        row.append(e)\n",
    "\n",
    "    # print(row)\n",
    "    dataset.append(row)\n",
    "    break\n",
    "\n",
    "#print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         rnic test_node test_type tx_depth   mtu  bg_msgsize     bg_bw  \\\n",
      "0    X6ETH100      Y301        wb      128  1024        1024   9288.93   \n",
      "1    X6ETH100      Y301        wb      128  1024     1048576  10820.53   \n",
      "2    X6ETH100      Y301        wb      128  1024  1073741824  10456.14   \n",
      "3    X6ETH100      Y301        wb      128  1024      131072  10784.72   \n",
      "4    X6ETH100      Y301        wb      128  1024       16384  10784.04   \n",
      "..        ...       ...       ...      ...   ...         ...       ...   \n",
      "163  X6ETH100      Y301        wb        2   512        4096   2165.29   \n",
      "164  X6ETH100      Y301        wb        2   512         512    331.83   \n",
      "165  X6ETH100      Y301        wb        2   512      524288  10030.66   \n",
      "166  X6ETH100      Y301        wb        2   512       65536  10080.47   \n",
      "167  X6ETH100      Y301        wb        2   512        8192   3653.15   \n",
      "\n",
      "    msgsize_tput  iter_tput bw_peak_tput  ... msgrate_tput msgsize_lat  \\\n",
      "0             16  100000000         0.00  ...     9.074382          16   \n",
      "1             16  100000000         0.00  ...     9.081211          16   \n",
      "2             16  100000000         0.00  ...     9.069217          16   \n",
      "3             16  100000000         0.00  ...     9.256898          16   \n",
      "4             16  100000000         0.00  ...     9.216793          16   \n",
      "..           ...        ...          ...  ...          ...         ...   \n",
      "163           16  100000000         0.00  ...    15.842016          16   \n",
      "164           16  100000000         0.00  ...    16.340021          16   \n",
      "165           16  100000000         0.00  ...    11.610785          16   \n",
      "166           16  100000000         0.00  ...    11.475160          16   \n",
      "167           16  100000000         0.00  ...    14.665553          16   \n",
      "\n",
      "     iter_lat t_min   t_max t_typical t_avg t_stdev 99th_percentile  \\\n",
      "0    10000000  1.05   17.88      1.28  1.30    0.33            1.54   \n",
      "1    10000000  1.06  235.72      1.29  1.57    0.86            2.37   \n",
      "2    10000000  1.05  249.72      1.29  1.56    0.81            2.20   \n",
      "3    10000000  1.06  250.86      1.26  1.52    0.91            2.27   \n",
      "4    10000000  1.05  249.82      1.28  1.57    0.82            2.42   \n",
      "..        ...   ...     ...       ...   ...     ...             ...   \n",
      "163  10000000  1.05   16.63      1.15  1.19    0.31            1.37   \n",
      "164  10000000  0.99   16.56      1.13  1.15    0.30            1.35   \n",
      "165  10000000  1.05  231.64      1.23  1.62    0.90            6.19   \n",
      "166  10000000  1.06   16.83      2.02  1.97    0.44            2.27   \n",
      "167  10000000  1.06   14.85      1.13  1.19    0.31            1.42   \n",
      "\n",
      "    99.9th_percentile  \n",
      "0                7.79  \n",
      "1                9.23  \n",
      "2                9.06  \n",
      "3                9.13  \n",
      "4                9.31  \n",
      "..                ...  \n",
      "163              7.65  \n",
      "164              7.57  \n",
      "165              9.65  \n",
      "166              8.56  \n",
      "167              7.59  \n",
      "\n",
      "[168 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(dataset, columns=columns)\n",
    "\n",
    "print(df)\n",
    "df.to_csv(OUTPUT)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "996a4fd48035787a0d8ee152fcdd352f02c743a60e71d5508e318f226822b2c7"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
